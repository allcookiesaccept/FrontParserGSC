# GSC Parser

**GSC Parser** — это инструмент парсинга данных из интерфейса Google Search Console (GSC), для случаев когда отсутствует возможность получить доступ к API или воспользоваться `Screaming Frog` и его сбором данных. 

Проект позволяет автоматизировать сбор ключевых метрик (клики, показы, CTR, средняя позиция) для списка URL за последние 28 дней.

---
## Основные возможности

- Поддержка ручного логина в Google Search Console (60 секунд на ввод данных).
- Сбор метрик: клики, показы, CTR, средняя позиция.
- Сохранение результатов в файл Excel (gsc_data.xlsx).
- Логирование процесса для отладки и мониторинга.
---
## Структура проекта
```text
gsc-parser/
│
├── app.py              # Основной скрипт для запуска парсера
├── utils/             # Утилиты и вспомогательные модули
│   ├── browser.py     # Настройка и управление веб-драйвером
│   ├── dataframes.py  # Сохранение данных в Excel
│   ├── encoder.py     # Кодирование URL для GSC
│   ├── logger.py      # Логирование
│   ├── parser.py      # Логика парсинга страниц GSC
│   └── settings.py    # Конфигурация и загрузка переменных окружения
├── logs/              # Директория для логов (создается автоматически)
├── urls.txt           # Файл со списком URL (создайте вручную)
├── gsc_data.xlsx      # Выходной файл с результатами
└── .env               # Файл с переменными окружения (опционально)

```


---
## Описание ключевых компонентов
- `app.py`: Управляет процессом — загрузка URL, логин, парсинг, сохранение данных.
- `browser.py`: Инициализирует Selenium WebDriver с настройками.
- `parser.py`: Содержит классы для работы с интерфейсом GSC (логин и сбор метрик).
- `encoder.py`: Генерирует закодированные URL для отчетов GSC.
- `dataframes.py`: Преобразует данные в pandas DataFrame и сохраняет в Excel.
- `logger.py`: Настраивает логирование в файл и консоль.